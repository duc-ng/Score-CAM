{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import getopt\n",
    "import pathlib\n",
    "import shutil\n",
    "import numpy as np\n",
    "from matplotlib.image import imsave\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from utils import load_image, apply_transforms_score, basic_visualize, visualize, save_output\n",
    "from cam.scorecam import ScoreCAM\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear results directory\n",
    "path_results = pathlib.Path('./results')\n",
    "if path_results.exists() and path_results.is_dir():\n",
    "    shutil.rmtree(path_results) #rm previous results\n",
    "path_results.mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target layer:  ReLU(inplace=True)\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00036091.JPEG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duc/anaconda3/envs/scorecam/lib/python3.10/site-packages/torch/nn/modules/module.py:1033: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00018439.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00033769.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00031754.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00030846.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00006427.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00025347.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00045946.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00022482.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00012034.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00044654.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00043191.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00046669.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00017236.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00026992.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00046393.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00020145.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00027680.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00009228.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00022178.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00001618.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00003625.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00028575.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00033293.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00002937.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00034556.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00049066.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00006077.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00033339.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00018069.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00031304.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00044204.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00012464.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00026838.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00024805.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00046239.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00025717.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00038826.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00009382.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00020515.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00016974.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00022528.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00009678.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00041006.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00017666.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00018593.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00049436.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00034106.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00001248.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00028125.JPEG\n",
      "/Users/duc/Downloads/ILSVRC2012_img_val/ILSVRC2012_val_00003275.JPEG\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/duc/Dropbox/Uni/M2.4 Project CV/Score-CAM/run.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/duc/Dropbox/Uni/M2.4%20Project%20CV/Score-CAM/run.ipynb#ch0000003?line=25'>26</a>\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/duc/Dropbox/Uni/M2.4%20Project%20CV/Score-CAM/run.ipynb#ch0000003?line=26'>27</a>\u001b[0m     input_ \u001b[39m=\u001b[39m input_\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/duc/Dropbox/Uni/M2.4%20Project%20CV/Score-CAM/run.ipynb#ch0000003?line=28'>29</a>\u001b[0m predicted_class \u001b[39m=\u001b[39m model(input_)\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/duc/Dropbox/Uni/M2.4%20Project%20CV/Score-CAM/run.ipynb#ch0000003?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m predicted_class \u001b[39m==\u001b[39m \u001b[39m243\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/duc/Dropbox/Uni/M2.4%20Project%20CV/Score-CAM/run.ipynb#ch0000003?line=30'>31</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m######################\u001b[39m\u001b[39m\"\u001b[39m, image)\n",
      "File \u001b[0;32m~/anaconda3/envs/scorecam/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/scorecam/lib/python3.10/site-packages/torchvision/models/vgg.py:66\u001b[0m, in \u001b[0;36mVGG.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> 66\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m     67\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m     68\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/scorecam/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/scorecam/lib/python3.10/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/scorecam/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/scorecam/lib/python3.10/site-packages/torch/nn/modules/conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 447\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/scorecam/lib/python3.10/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    441\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    442\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 443\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    444\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## EXPERIMENT 1: Class discrimination\n",
    "\n",
    "# init\n",
    "TARGET_LAYER = \"features.29\"\n",
    "IMAGE_DIR = \"/Users/duc/Downloads/ILSVRC2012_img_val\"\n",
    "MEANS = [0.485, 0.456, 0.406]\n",
    "STDS = [0.229, 0.224, 0.225]\n",
    "SIZE = 224\n",
    "\n",
    "# load model\n",
    "model = models.vgg16(pretrained=True).eval()\n",
    "model_scorecam = ScoreCAM(dict(arch=model, layer_name=TARGET_LAYER, input_size=(SIZE, SIZE)))\n",
    "\n",
    "# load images\n",
    "images = glob(join(IMAGE_DIR, \"*\"))\n",
    "\n",
    "# preprocess image + generate heatmaps\n",
    "for image in images:\n",
    "    try:\n",
    "        input_image = load_image(image)  \n",
    "    except:\n",
    "        print(\"Error:\", image)\n",
    "    else:\n",
    "        input_ = apply_transforms_score(input_image, MEANS, STDS, SIZE)\n",
    "        if torch.cuda.is_available():\n",
    "            input_ = input_.cuda()\n",
    "\n",
    "        predicted_class = model(input_).max(1)[-1]\n",
    "        if predicted_class == 243:\n",
    "            print(\"######################\", image)\n",
    "    \n",
    "\n",
    "# visualize heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('scorecam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34148f8ae5953039ad03c77ad3820a29bb60621b2fadaa00a65434671a38f77d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
